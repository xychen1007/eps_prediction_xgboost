{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Portfolio_Construction_Notebook_Group17.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2Im2p7dk8xC1"},"source":["# Imports"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j3bj9Df_8xC3","outputId":"a6c6a163-58d3-4651-a698-d90dba07b90b","executionInfo":{"status":"ok","timestamp":1589807531947,"user_tz":240,"elapsed":682,"user":{"displayName":"Xiaoyu Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYb2XrHzjJJMEznZMIpAWInIKxnQ4P07KKtgZh=s64","userId":"13326746028563113786"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import itertools\n","#import talib\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","from statsmodels.graphics.tsaplots import plot_acf\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import mean_squared_error\n","\n","import xgboost as xgb\n","from sklearn.metrics import accuracy_score\n","import seaborn as sns\n","import operator\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","plt.rc('figure', figsize=(20, 8), dpi=100)\n","from datetime import datetime"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CTvUe-Hw8_cc"},"source":["# Classes and Functions"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JhswmZ1A9Dev"},"source":["Classes to train the regressor given data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5dgINEZX8xC8","colab":{}},"source":["\n","\n","class Plot:\n","    \n","    def __init__(self, data):\n","        self.data = data\n","        \n","    def autocorr(self, col, ticker):\n","        \n","        plot_acf(self.data[col], title = col + ' Autocorrelation Plot of ' + ticker)\n","        plt.show()\n","            \n","    def featureImportance(self, feature_importance, num_features, flag, ticker):\n","    \n","        f = dict()\n","        n = len(feature_importance)\n","        for i in range (n):\n","            f[X_test.columns[i]] = feature_importance[i]\n","        f = sorted(f.items(), key=operator.itemgetter(1), reverse=True)\n","        f = f[:num_features]\n","        feature_name = list()\n","        feature_values = list()\n","        for i, j in f:\n","            feature_name.append(i)\n","            feature_values.append(j)\n","        fig = plt.figure(figsize=(14,5))\n","        plt.xticks(rotation='vertical')\n","        plt.bar([i for i in range(len(f))], feature_values, tick_label=feature_name)\n","        if flag == 1:\n","            plt.title('Feature importance for EPS Prediction of ' + ticker + ' (Excluding Analyst estimate features)')\n","        else:\n","            plt.title('Feature importance for EPS Prediction of ' + ticker + ' (Including Analyst estimate features)')\n","        plt.show()\n","    \n","    def lossStatsAndCurve(self, X_test, Y_test, regressor, ticker):\n","        \n","        \n","        rmse = np.sqrt(mean_squared_error(Y_test, regressor.predict(X_test)))\n","        print(\"Root Mean Squared Error: %f\" % (rmse))\n","        #print (\"Regression Prediction Score: \" + str(round(regressor.score(X_test,Y_test) * 100, 2)) + \"%\")\n","        eval_result = regressor.evals_result()\n","        training_rounds = range(len(eval_result['validation_0']['rmse']))\n","        plt.scatter(x=training_rounds,y=eval_result['validation_0']['rmse'],label='Training Error')\n","        plt.scatter(x=training_rounds,y=eval_result['validation_1']['rmse'],label='Validation Error')\n","        plt.xlabel('Iterations')\n","        plt.ylabel('RMSE')\n","        plt.title('Training Vs Validation Error of ' + ticker)\n","        plt.legend()\n","        plt.show()\n","\n","class Model:\n","    def __init__(self, X_train, Y_train, X_test, Y_test):\n","        \n","        self.X_train = X_train\n","        self.Y_train = Y_train\n","        self.X_test = X_test\n","        self.Y_test = Y_test\n","    \n","    def trainModel(self, epoch = 1000, verbose_flag = False, learning_rate = 0.01):\n","        \n","        regressor = xgb.XGBRegressor(colsample_bytree = 0.4, learning_rate = learning_rate, base_score=0.65, max_depth = 4, alpha = 10, n_estimators = epoch)\n","        xgbModel=regressor.fit(X_train, Y_train,eval_set = [(X_train, Y_train), (X_test, Y_test)], verbose = verbose_flag)\n","        return (xgbModel, regressor)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jc62-zzG9RYA"},"source":["Functions to get data, either for all time or from beginning of time up until the specified date"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KJfY4fBT8xDA","colab":{}},"source":["def getData(data_temp, inc_analyst):\n","    \n","    data = data_temp.copy()\n","    Y = data['EPS (diluted)']\n","    \n","    del data['EPS (recurring)']\n","    del data['EPS (diluted)']\n","    \n","    if inc_analyst == False:\n","        #del data['Growth (YoY%)_Analyst']\n","        del data['EPS_Analyst']\n","    X = data\n","    \n","    train_samples = int(X.shape[0] * 0.75)\n","     \n","    X_train = X.iloc[:train_samples]\n","    X_test = X.iloc[train_samples:]\n","\n","    Y_train = Y.iloc[:train_samples]\n","    Y_test = Y.iloc[train_samples:]\n","    \n","    \n","    return (X_train, Y_train), (X_test, Y_test)\n","\n","def getDataUntilDate(data_temp, data_dates, startingDate, stoppingDate):\n","    data = data_temp.copy()\n","    Y = data['EPS (diluted)']\n","    \n","    del data['EPS (recurring)']\n","    del data['EPS (diluted)']\n","    \n","    X = data\n","    n = X.shape[0]\n","    for i in range(n):\n","        if (data_dates[i] > startingDate):\n","            beginIndex = i\n","            break\n","    \n","    lastIndex = beginIndex+1\n","    for i in range(beginIndex, n):\n","        if (data_dates[i] > stoppingDate):\n","            lastIndex = i\n","            break\n","        \n","    X_train = X.iloc[range(beginIndex,lastIndex)]\n","    Y_train = Y.iloc[range(beginIndex,lastIndex)]\n","    X_test = X.iloc[range(lastIndex, lastIndex+5)]\n","    Y_test = Y.iloc[range(lastIndex, lastIndex+5)]\n","        \n","    return (X_train, Y_train), (X_test, Y_test)\n","\n","def getDataUntilDateforROA(data_temp, data_dates, startingDate, stoppingDate):\n","    data = data_temp.copy()\n","    Y = data['Return on Assets (%)']\n","    \n","    del data['Return on Assets (%)']\n","    #del data['EPS (diluted)']\n","    \n","    X = data\n","    n = X.shape[0]\n","    for i in range(n):\n","        if (data_dates[i] > startingDate):\n","            beginIndex = i\n","            break\n","    \n","    lastIndex = beginIndex+1\n","    for i in range(beginIndex, n):\n","        if (data_dates[i] > stoppingDate):\n","            lastIndex = i\n","            break\n","        \n","    X_train = X.iloc[range(beginIndex,lastIndex)]\n","    Y_train = Y.iloc[range(beginIndex,lastIndex)]\n","    X_test = X.iloc[range(lastIndex, lastIndex+5)]\n","    Y_test = Y.iloc[range(lastIndex, lastIndex+5)]\n","        \n","    return (X_train, Y_train), (X_test, Y_test)\n","\n","def getDataUntilDateforROE(data_temp, data_dates, startingDate, stoppingDate):\n","    data = data_temp.copy()\n","    Y = data['Return on Equity (%)']\n","    \n","    del data['Return on Equity (%)']\n","    #del data['EPS (diluted)']\n","    \n","    X = data\n","    n = X.shape[0]\n","    for i in range(n):\n","        if (data_dates[i] > startingDate):\n","            beginIndex = i\n","            break\n","    \n","    lastIndex = beginIndex+1\n","    for i in range(beginIndex, n):\n","        if (data_dates[i] > stoppingDate):\n","            lastIndex = i\n","            break\n","        \n","    X_train = X.iloc[range(beginIndex,lastIndex)]\n","    Y_train = Y.iloc[range(beginIndex,lastIndex)]\n","    X_test = X.iloc[range(lastIndex, lastIndex+5)]\n","    Y_test = Y.iloc[range(lastIndex, lastIndex+5)]\n","        \n","    return (X_train, Y_train), (X_test, Y_test)\n","\n","def getDataUntilDateforFCF(data_temp, data_dates, startingDate, stoppingDate):\n","    data = data_temp.copy()\n","    Y = data['Free Cash Flow per Share']\n","    \n","    del data['Free Cash Flow per Share']\n","    if 'Free Cash Flow Yield' in data.columns:\n","      del data['Free Cash Flow Yield']\n","    if 'Free Cash Flow_x' in data.columns:\n","      del data['Free Cash Flow_x']\n","    if 'Free Cash Flow_y' in data.columns:\n","      del data['Free Cash Flow_y']  \n","    \n","    \n","    X = data\n","    n = X.shape[0]\n","    for i in range(n):\n","        if (data_dates[i] > startingDate):\n","            beginIndex = i\n","            break\n","    \n","    lastIndex = beginIndex+1\n","    for i in range(beginIndex, n):\n","        if (data_dates[i] > stoppingDate):\n","            lastIndex = i\n","            break\n","        \n","    X_train = X.iloc[range(beginIndex,lastIndex)]\n","    Y_train = Y.iloc[range(beginIndex,lastIndex)]\n","    X_test = X.iloc[range(lastIndex, lastIndex+5)]\n","    Y_test = Y.iloc[range(lastIndex, lastIndex+5)]\n","        \n","    return (X_train, Y_train), (X_test, Y_test)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PAngyUic9Uyi"},"source":["Functions to create portfolio weights, given the predicted EPS. The formulas and explanations / rationales of each flavor is outlined in the final report document. The functions createPortfolio1/2/3 correspond to flavor A,B,C in the report respectively. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4ZaePEpJ8xDD","colab":{}},"source":["def createPortfolio1(predDf, dataset, datasetDates, long_only = False, exclude_citi = False):\n","    \"\"\"\n","    predDf: a df each line representing date and prediction of different stocks on that certain date\n","    dataset: a list with each element a df of a stock\n","    datasetDates: a list with each element as the column 'Date' of each stock \n","    return a df weight with first column as date and later columns as stocks. each element represents the proportion of \n","    a certain stock in a certain date.\n","    \"\"\"\n","    n = predDf.shape[0]#number of dates\n","    weightColumns = predDf.columns[1:]\n","    weightDf = pd.DataFrame(columns = weightColumns)\n","    k = len(weightColumns)\n","\n","    for i in range(n):\n","        #loop over each date in the prediction dataframe\n","        currRow = predDf.iloc[i]\n","        currDate = currRow['Date']\n","        proportions = np.zeros(k-1)\n","        for j in range(1,k):\n","            #loop over each stock in ith date\n","            eps = currRow[weightColumns[j]]\n","            df = dataset[j-1]\n","            dfDates = datasetDates[j-1]\n","            for ii in range(len(dfDates)):\n","                if (dfDates[ii] > currDate):\n","                    foundIndex = ii\n","                    break\n","            \n","            if (foundIndex >= len(df)):\n","                foundIndex = len(df) - 1\n","            \n","            closePrice = df.iloc[foundIndex]['Close'] # for each stock in each date, find the close Price\n","            \n","            \n","            proportions[j-1] = eps / closePrice\n","            if (long_only and proportions[j-1] < 0):\n","                proportions[j-1] = 0\n","            if (exclude_citi and ((j-1) == ticker.index('Citigroup'))):\n","                proportions[j-1] = 0\n","        \n","        if (long_only and sum(proportions) == 0):\n","            proportions[:] = 1\n","        proportions = proportions / sum(proportions)\n","        weightDict = {}\n","        weightDict['Date'] = currDate\n","        for j in range(1,k):\n","            weightDict[weightColumns[j]] = proportions[j-1]\n","        #weightDict = {'Date': '2010-10-01', 'Apple':0.2, 'Amazon':0.1....}\n","        weightDf = weightDf.append(weightDict, ignore_index = True)\n","        \n","    return weightDf\n","\n","def createPortfolio2(predDf, dataset, datasetDates, long_only = False, exclude_citi = False):\n","    n = predDf.shape[0]\n","    weightColumns = predDf.columns[1:]\n","    weightDf = pd.DataFrame(columns = weightColumns)\n","    k = len(weightColumns)\n","\n","    for i in range(n):\n","        currRow = predDf.iloc[i]\n","        currDate = currRow['Date']\n","        proportions = np.zeros(k-1)\n","        for j in range(1,k):\n","            eps = currRow[weightColumns[j]]\n","            df = dataset[j-1]\n","            dfDates = datasetDates[j-1]\n","            for ii in range(len(dfDates)):\n","                if (dfDates[ii] > currDate):\n","                    foundIndex = ii\n","                    break\n","            if (foundIndex >= len(df)):\n","                foundIndex = len(df) - 1\n","            \n","            analyst = df.iloc[foundIndex].get('EPS_Analyst')\n","            if (analyst == None):\n","                proportions[j-1] = 0\n","            else:\n","                proportions[j-1] = (eps - analyst) / eps\n","\n","            if (long_only and proportions[j-1] < 0):\n","                proportions[j-1] = 0\n","            if (exclude_citi and ((j-1) == ticker.index('Citigroup'))):\n","                proportions[j-1] = 0\n","        \n","        if (long_only and sum(proportions) == 0):\n","            proportions[:] = 1\n","\n","        proportions = proportions / sum(proportions)\n","        weightDict = {}\n","        weightDict['Date'] = currDate\n","        for j in range(1,k):\n","            weightDict[weightColumns[j]] = proportions[j-1]\n","        \n","        weightDf = weightDf.append(weightDict, ignore_index = True)\n","        \n","    return weightDf\n","\n","def createPortfolio3(predDf, dataset, datasetDates, long_only = False, exclude_citi = False):\n","    n = predDf.shape[0]\n","    weightColumns = predDf.columns[1:]\n","    weightDf = pd.DataFrame(columns = weightColumns)\n","    k = len(weightColumns)\n","\n","    for i in range(n):\n","        currRow = predDf.iloc[i]\n","        currDate = currRow['Date']\n","        proportions = np.zeros(k-1)\n","        for j in range(1,k):\n","            eps = currRow[weightColumns[j]]\n","            df = dataset[j-1]\n","            dfDates = datasetDates[j-1]\n","            for ii in range(len(dfDates)):\n","                if (dfDates[ii] > currDate):\n","                    foundIndex = ii\n","                    break\n","\n","            if (foundIndex >= len(df)):\n","                foundIndex = len(df) - 1\n","\n","            startDateToConsider = datetime(currDate.year-1, currDate.month, 1)  \n","            for jj in range(len(dfDates)):\n","                if (dfDates[jj] > startDateToConsider):\n","                    startDateIndex = jj\n","                    break\n","            \n","            analyst = df.iloc[foundIndex].get('EPS_Analyst')\n","            if (analyst == None):\n","                proportions[j-1] = 0\n","            else:\n","                proportions[j-1] = (eps - analyst) / analyst\n","\n","            if (long_only and proportions[j-1] < 0):\n","                proportions[j-1] = 0\n","            if (exclude_citi and ((j-1) == ticker.index('Citigroup'))):\n","                proportions[j-1] = 0\n","        \n","        if (long_only and sum(proportions) == 0):\n","            proportions[:] = 1\n","        proportions = proportions / sum(proportions)\n","        weightDict = {}\n","        weightDict['Date'] = currDate\n","        for j in range(1,k):\n","            weightDict[weightColumns[j]] = proportions[j-1]\n","        \n","        weightDf = weightDf.append(weightDict, ignore_index = True)\n","        \n","    return weightDf\n","\n","\n","def createPortfolio4(predDf, dataset, datasetDates, long_only = False, exclude_citi = False):\n","    n = predDf.shape[0]\n","    weightColumns = predDf.columns[1:]\n","    weightDf = pd.DataFrame(columns = weightColumns)\n","    k = len(weightColumns)\n","\n","    for i in range(n):\n","        currRow = predDf.iloc[i]\n","        currDate = currRow['Date']\n","        proportions = np.zeros(k-1)\n","        for j in range(1,k):\n","            eps = currRow[weightColumns[j]]\n","            df = dataset[j-1]\n","            dfDates = datasetDates[j-1]\n","            for ii in range(len(dfDates)):\n","                if (dfDates[ii] > currDate):\n","                    foundIndex = ii\n","                    break\n","            \n","            if (foundIndex >= len(df)):\n","                foundIndex = len(df) - 1\n","            \n","            closePrice = df.iloc[foundIndex]['Close']\n","            \n","            if foundIndex < 365:\n","              indexof52high = df.iloc[:foundIndex]['Close'].idxmax()\n","            else:\n","              indexof52high = df.iloc[foundIndex-365:foundIndex]['Close'].idxmax()\n","            \n","            daysSince52high = foundIndex - indexof52high\n","            recencyRatio = (daysSince52high / 3650)\n","            #print(\"daysSince52high \" + str(daysSince52high))\n","            proportions[j-1] = (eps / closePrice) - (recencyRatio)\n","            if (long_only and proportions[j-1] < 0):\n","                proportions[j-1] = 0\n","            if (exclude_citi and ((j-1) == ticker.index('Citigroup'))):\n","                proportions[j-1] = 0\n","        \n","        if (long_only and sum(proportions) == 0):\n","            proportions[:] = 1\n","        proportions = proportions / sum(proportions)\n","        weightDict = {}\n","        weightDict['Date'] = currDate\n","        for j in range(1,k):\n","            weightDict[weightColumns[j]] = proportions[j-1]\n","        \n","        weightDf = weightDf.append(weightDict, ignore_index = True)\n","        \n","    return weightDf\n","\n","def createPortfolio5(predDf, dataset, datasetDates, long_only = False, exclude_citi = False):\n","    n = predDf.shape[0]\n","    weightColumns = predDf.columns[1:]\n","    weightDf = pd.DataFrame(columns = weightColumns)\n","    k = len(weightColumns)\n","\n","    for i in range(n):\n","        currRow = predDf.iloc[i]\n","        currDate = currRow['Date']\n","        proportions = np.zeros(k-1)\n","        for j in range(1,k):\n","            eps = currRow[weightColumns[j]]\n","            df = dataset[j-1]\n","            dfDates = datasetDates[j-1]\n","            for ii in range(len(dfDates)):\n","                if (dfDates[ii] > currDate):\n","                    foundIndex = ii\n","                    break\n","            if (foundIndex >= len(df)):\n","                foundIndex = len(df) - 1\n","            \n","            if foundIndex < 365:\n","              indexof52high = df.iloc[:foundIndex]['Close'].idxmax()\n","            else:\n","              indexof52high = df.iloc[foundIndex-365:foundIndex]['Close'].idxmax()\n","            \n","            daysSince52high = foundIndex - indexof52high\n","            recencyRatio = (daysSince52high / 3650)\n","            #print(\"daysSince52high \" + str(daysSince52high))\n","\n","            analyst = df.iloc[foundIndex].get('EPS_Analyst')\n","            if (analyst == None):\n","                proportions[j-1] = 0\n","            else:\n","                proportions[j-1] = ((eps - analyst) / eps) - (recencyRatio)\n","\n","\n","\n","            if (long_only and proportions[j-1] < 0):\n","                proportions[j-1] = 0\n","            if (exclude_citi and ((j-1) == ticker.index('Citigroup'))):\n","                proportions[j-1] = 0\n","        \n","        if (long_only and sum(proportions) == 0):\n","            proportions[:] = 1\n","\n","        proportions = proportions / sum(proportions)\n","        weightDict = {}\n","        weightDict['Date'] = currDate\n","        for j in range(1,k):\n","            weightDict[weightColumns[j]] = proportions[j-1]\n","        \n","        weightDf = weightDf.append(weightDict, ignore_index = True)\n","        \n","    return weightDf\n","\n","def createPortfolio6(predDf, dataset, datasetDates, long_only = False, exclude_citi = False):\n","    n = predDf.shape[0]\n","    weightColumns = predDf.columns[1:]\n","    weightDf = pd.DataFrame(columns = weightColumns)\n","    k = len(weightColumns)\n","\n","    for i in range(n):\n","        currRow = predDf.iloc[i]\n","        currDate = currRow['Date']\n","        proportions = np.zeros(k-1)\n","        for j in range(1,k):\n","            eps = currRow[weightColumns[j]]\n","            df = dataset[j-1]\n","            dfDates = datasetDates[j-1]\n","            for ii in range(len(dfDates)):\n","                if (dfDates[ii] > currDate):\n","                    foundIndex = ii\n","                    break\n","\n","            if (foundIndex >= len(df)):\n","                foundIndex = len(df) - 1\n","\n","            startDateToConsider = datetime(currDate.year-1, currDate.month, 1)  \n","            for jj in range(len(dfDates)):\n","                if (dfDates[jj] > startDateToConsider):\n","                    startDateIndex = jj\n","                    break\n","           \n","            if foundIndex < 365:\n","              indexof52high = df.iloc[:foundIndex]['Close'].idxmax()\n","            else:\n","              indexof52high = df.iloc[foundIndex-365:foundIndex]['Close'].idxmax()\n","            \n","            daysSince52high = foundIndex - indexof52high\n","            recencyRatio = (daysSince52high / 3650)\n","            #print(\"daysSince52high \" + str(daysSince52high))\n","\n","            analyst = df.iloc[foundIndex].get('EPS_Analyst')\n","            if (analyst == None):\n","                proportions[j-1] = 0\n","            else:\n","                proportions[j-1] = ((eps - analyst) / analyst) - recencyRatio\n","\n","            if (long_only and proportions[j-1] < 0):\n","                proportions[j-1] = 0\n","            if (exclude_citi and ((j-1) == ticker.index('Citigroup'))):\n","                proportions[j-1] = 0\n","        \n","        if (long_only and sum(proportions) == 0):\n","            proportions[:] = 1\n","        proportions = proportions / sum(proportions)\n","        weightDict = {}\n","        weightDict['Date'] = currDate\n","        for j in range(1,k):\n","            weightDict[weightColumns[j]] = proportions[j-1]\n","        \n","        weightDf = weightDf.append(weightDict, ignore_index = True)\n","        \n","    return weightDf\n","\n","def createPortfolio7(predDf, predDfROA, predDfFCF, predDfROE, dataset, datasetDates, long_only = False, exclude_citi = False):\n","    n = predDf.shape[0]\n","    weightColumns = predDf.columns[1:]\n","    weightDf = pd.DataFrame(columns = weightColumns)\n","    k = len(weightColumns)\n","\n","    for i in range(n):\n","        currRow = predDf.iloc[i]\n","        currRowROA = predDfROA.iloc[i]\n","        currRowFCF = predDfFCF.iloc[i]\n","        currRowROE = predDfROE.iloc[i]\n","        currDate = currRow['Date']\n","        proportions = np.zeros(k-1)\n","        for j in range(1,k):\n","            eps = currRow[weightColumns[j]]\n","            roa = currRowROA[weightColumns[j]]\n","            fcf = currRowFCF[weightColumns[j]]\n","            roe = currRowROE[weightColumns[j]]\n","            df = dataset[j-1]\n","            dfDates = datasetDates[j-1]\n","            for ii in range(len(dfDates)):\n","                if (dfDates[ii] > currDate):\n","                    foundIndex = ii\n","                    break\n","            \n","            if (foundIndex >= len(df)):\n","                foundIndex = len(df) - 1\n","            \n","            closePrice = df.iloc[foundIndex]['Close']\n","            \n","            if foundIndex < 365:\n","              indexof52high = df.iloc[:foundIndex]['Close'].idxmax()\n","              pastroa = df.iloc[:foundIndex]['Return on Assets (%)'].mean()\n","              pastfcf = df.iloc[:foundIndex]['Free Cash Flow per Share'].mean()\n","              pastroe = df.iloc[:foundIndex]['Return on Equity (%)'].mean()\n","            else:\n","              indexof52high = df.iloc[foundIndex-365:foundIndex]['Close'].idxmax()\n","              pastroa = df.iloc[foundIndex-365:foundIndex]['Return on Assets (%)'].mean()\n","              pastfcf = df.iloc[foundIndex-365:foundIndex]['Free Cash Flow per Share'].mean()\n","              pastroe = df.iloc[foundIndex-365:foundIndex]['Return on Equity (%)'].mean()\n","\n","            daysSince52high = foundIndex - indexof52high\n","            recencyRatio = (daysSince52high / 3650)\n","\n","            roaPoint = (roa - pastroa) / (10 * pastroa)\n","            fcfPoint = (fcf - pastfcf) / (10 * pastfcf)\n","            roePoint = (roe - pastroe) / (10 * pastroe)\n","            \n","            analyst = df.iloc[foundIndex].get('EPS_Analyst')\n","            if (analyst == None):\n","                proportions[j-1] = 0\n","            else:\n","                proportions[j-1] = ((eps - analyst) / analyst) - recencyRatio + roaPoint + roePoint + fcfPoint\n","            if (long_only and proportions[j-1] < 0):\n","                proportions[j-1] = 0\n","            if (exclude_citi and ((j-1) == ticker.index('Citigroup'))):\n","                proportions[j-1] = 0\n","        \n","        if (long_only and sum(proportions) == 0):\n","            proportions[:] = 1\n","        proportions = proportions / sum(proportions)\n","        weightDict = {}\n","        weightDict['Date'] = currDate\n","        for j in range(1,k):\n","            weightDict[weightColumns[j]] = proportions[j-1]\n","        \n","        weightDf = weightDf.append(weightDict, ignore_index = True)\n","        \n","    return weightDf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mGCWSlcF9kPH"},"source":["Function to calculate returns and portfolio \"NAVs\" given the asset weights and asset prices."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6_YBTG8I8xDH","colab":{}},"source":["def calcReturns(weights, dataset, datasetDates):\n","    \"\"\"\n","    weights: a list with each element a dataframe returned by createportfolio\n","    dataset: a list with each element a df of a stock\n","    datasetDates: a list with each element as the column 'Date' of each stock \n","    \n","    return a 2-d np.array with each line a date and each column a portfolio. elements in cells are prices.\n","    \"\"\"\n","    #n means number of dates\n","    #m means different kinds of portfolio\n","    n = weights[0].shape[0]\n","    m = len(weights)\n","    weightColumns = weights[0].columns[2:]\n","    k = len(weightColumns)    \n","\n","    prices = np.zeros([n,m])\n","    for j in range(m):\n","        prices[0,j] = 100\n","        \n","    for i in range(1,n):\n","        periodStartDate = weights[0].iloc[i-1].Date\n","        periodEndDate = weights[0].iloc[i].Date\n","        prch = np.zeros(k)\n","        \n","        for j in range(k):\n","            # find price change of asset j between periodStartDate and periodEndDate\n","            df = dataset[j]\n","            dfDates = datasetDates[j]\n","            for ii in range(len(dfDates)):\n","                if(dfDates[ii] >= periodStartDate):\n","                    startIndex = ii\n","                    break\n","            \n","            for ii in range(startIndex, len(dfDates)):\n","                if(dfDates[ii] >= periodEndDate):\n","                    endIndex = ii\n","                    break\n","\n","            if (startIndex >= len(df)):\n","                startIndex = len(df) - 1\n","            if (endIndex >= len(df)):\n","                endIndex = len(df) - 1\n","                \n","            startPrice = df.iloc[startIndex]['Close']    \n","            endPrice = df.iloc[endIndex]['Close']\n","            prch[j] = (endPrice - startPrice) / startPrice\n","        \n","        for j in range(m):\n","            totalPrch = 0\n","            for jj in range(k):\n","                totalPrch = totalPrch + weights[j].iloc[i][weightColumns[jj]] * prch[jj]\n","            prevPrice = prices[i-1,j]\n","            nextPrice = prevPrice * (1+totalPrch)\n","            prices[i,j] = nextPrice\n","    \n","    return prices\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YB6ejV5_55wL","colab_type":"code","colab":{}},"source":["def calcReturns_fee(weights, dataset, datasetDates, fee_rate = 0.001):\n","    \"\"\"\n","    weights: dataframe returned by createportfolio\n","    dataset: a list with each element a df of a stock\n","    datasetDates: a list with each element as the column 'Date' of each stock \n","    \n","    return a 2-d np.array with each line a date and each column a portfolio. elements in cells are prices.\n","    \"\"\"\n","    #n means number of dates\n","    #m means different kind of portfolio\n","    n = weights[0].shape[0]\n","    m = len(weights)\n","    weightColumns = weights[0].columns[2:]\n","    k = len(weightColumns)    \n","\n","    prices = np.zeros([n,m])\n","    fee = np.zeros([n,m])\n","    for j in range(m):\n","        prices[0,j] = 100\n","        fee[0,j] = prices[0,j]*fee_rate\n","        \n","    for i in range(1,n):\n","        periodStartDate = weights[0].iloc[i-1].Date\n","        periodEndDate = weights[0].iloc[i].Date\n","        prch = np.zeros(k)\n","        \n","        for j in range(k):\n","            # find price change of asset j between periodStartDate and periodEndDate\n","            df = dataset[j]\n","            dfDates = datasetDates[j]\n","            for ii in range(len(dfDates)):\n","                if(dfDates[ii] >= periodStartDate):\n","                    startIndex = ii\n","                    break\n","            \n","            for ii in range(startIndex, len(dfDates)):\n","                if(dfDates[ii] >= periodEndDate):\n","                    endIndex = ii\n","                    break\n","\n","            if (startIndex >= len(df)):\n","                startIndex = len(df) - 1\n","            if (endIndex >= len(df)):\n","                endIndex = len(df) - 1\n","                \n","            startPrice = df.iloc[startIndex]['Close']    \n","            endPrice = df.iloc[endIndex]['Close']\n","            prch[j] = (endPrice - startPrice) / startPrice\n","        \n","        for j in range(m):\n","            #loop over different portfolios\n","            totalPrch = 0\n","            totalfee = 0\n","            for jj in range(k):\n","                totalPrch = totalPrch + weights[j].iloc[i][weightColumns[jj]] * prch[jj]\n","                totalfee = totalfee + abs(weights[j].iloc[i][weightColumns[jj]]-weights[j].iloc[i-1][weightColumns[jj]])*pr[jj]*fee_rate\n","            prevPrice = prices[i-1,j]\n","            nextPrice = prevPrice * (1+totalPrch)\n","            prices[i,j] = nextPrice\n","            fee[i,j] = totalfee\n","    \n","    return prices, fee\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0qcEQW5v9tQw"},"source":["Function to calculate statistics (tracking error, alpha, information ratio) against the benchmark, given the prices of both our portfolio and benchmark index. It also plots the price movement over time."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EYiHJepk8xDN","colab":{}},"source":["def plotAgainstSP(prices, weight, spPrices, title = '', imageFile = ''):\n","    n = prices.shape[0]\n","    m = prices.shape[1]-1\n","    \n","    spCleanPrices = np.zeros(n)\n","    spCleanPrices[0] = 100\n","    \n","    relatives = np.zeros([n-1,m])\n","    absolutes = np.zeros([n-1,m])\n","    for i in range(1,n):\n","        endDate = weight.Date[i]\n","        startDate = weight.Date[i-1]\n","        for ii in range(len(spPrices.Date)):\n","            if(spPrices.Date[ii] >= startDate):\n","                startIndex = ii\n","                break\n","        for ii in range(startIndex,len(spPrices.Date)):\n","            if(spPrices.Date[ii] >= endDate):\n","                endIndex = ii\n","                break\n","        startSpPrice = spPrices.Price[startIndex]\n","        endSpPrice = spPrices.Price[endIndex]\n","        spPrch = (endSpPrice - startSpPrice) / startSpPrice\n","        spCleanPrices[i] = (spPrch + 1) * spCleanPrices[i-1]\n","        for j in range(m):\n","            start = prices.iloc[i-1][j]\n","            end = prices.iloc[i][j]\n","            prch = (end - start) / start\n","            relatives[i-1,j] = prch - spPrch\n","            absolutes[i-1,j] = prch\n","    \n","    # Calculate analytics\n","    trackingErrors = np.std(relatives,0)\n","    alphas = np.sum(relatives,0)\n","    ir = np.zeros(m)\n","    \n","    returns = np.sum(absolutes,0)\n","    vols = np.std(absolutes,0)\n","    sharpes = np.zeros(m)\n","    \n","    for j in range(m):\n","        ir[j] = alphas[j] / trackingErrors[j]\n","        sharpes[j] = returns[j] / vols[j]\n","    \n","    totalData = prices.copy()\n","    totalData['SP_Index'] = spCleanPrices\n","    totalData['Date'] = weight.Date\n","    plt.figure()\n","    labs = [\"PrevGrp1\",\"PrevGrp2\",\"PrevGrp3\",\"wRR1\",\"wRR2\",\"wRR3\",\"wPoints\"]\n","    for j in range(m):\n","        plt.plot( totalData.Date, totalData[j],label = labs[j])\n","    plt.plot(totalData.Date, totalData.SP_Index,label = 'SP')\n","    plt.title(title)\n","    plt.legend()\n","    plt.savefig(imageFile)\n","    \n","    print(title)\n","    print(ir)\n","\n","    return relatives, absolutes, trackingErrors, alphas, ir, returns, vols, sharpes, spCleanPrices\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vV5iJ9N55wQ","colab_type":"code","colab":{}},"source":["def plotAgainstSP_fee(prices, weight, fee, spPrices, title = '', imageFile = ''):\n","    n = prices.shape[0]\n","    m = prices.shape[1]-1\n","    \n","    spCleanPrices = np.zeros(n)\n","    spCleanPrices[0] = 100\n","    \n","    relatives = np.zeros([n-1,m])\n","    absolutes = np.zeros([n-1,m])\n","    for i in range(1,n):\n","        endDate = weight.Date[i]\n","        startDate = weight.Date[i-1]\n","        for ii in range(len(spPrices.Date)):\n","            if(spPrices.Date[ii] >= startDate):\n","                startIndex = ii\n","                break\n","        for ii in range(startIndex,len(spPrices.Date)):\n","            if(spPrices.Date[ii] >= endDate):\n","                endIndex = ii\n","                break\n","        startSpPrice = spPrices.Price[startIndex]\n","        endSpPrice = spPrices.Price[endIndex]\n","        spPrch = (endSpPrice - startSpPrice) / startSpPrice\n","        spCleanPrices[i] = (spPrch + 1) * spCleanPrices[i-1]\n","        for j in range(m):\n","            start = prices.iloc[i-1][j]\n","            end = prices.iloc[i][j]\n","            cur_fee = fee.iloc[i][j]\n","            prch = (end - start - cur_fee) / start\n","            relatives[i-1,j] = prch - spPrch\n","            absolutes[i-1,j] = prch\n","    \n","    # Calculate analytics\n","    trackingErrors = np.std(relatives,0)\n","    alphas = np.sum(relatives,0)\n","    ir = np.zeros(m)\n","    \n","    returns = np.sum(absolutes,0)\n","    vols = np.std(absolutes,0)\n","    sharpes = np.zeros(m)\n","    \n","    for j in range(m):\n","        ir[j] = alphas[j] / trackingErrors[j]\n","        sharpes[j] = returns[j] / vols[j]\n","    \n","    totalData = prices.copy()\n","    totalData['SP_Index'] = spCleanPrices\n","    totalData['Date'] = weight.Date\n","    plt.figure()\n","    labs = [\"PrevGrp1\",\"PrevGrp2\",\"PrevGrp3\",\"wRR1\",\"wRR2\",\"wRR3\",\"wPoints\"]\n","    for j in range(m):\n","        plt.plot( totalData.Date, totalData[j],label = labs[j])\n","    plt.plot(totalData.Date, totalData.SP_Index,label = 'SP')\n","    plt.title(title)\n","    plt.legend()\n","    plt.savefig(imageFile)\n","    \n","    print(title)\n","    print(ir)\n","\n","    return relatives, absolutes, trackingErrors, alphas, ir, returns, vols, sharpes, spCleanPrices"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rBDeWDQK97Bw"},"source":["# Main Code"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pv18fBvq9-Hc"},"source":["These are flags to control whether we want to redo prediction, construction, and simulation steps. They should all be True, but if you have run them previously and have the excel file saved, you can set some steps to False and just reuse the previously-computed Excel file to save time. \n","\n","The Excel files also help us investigate why certain portfolios are doing really well / really poorly etc, by finding out abnormally high weight percentage of a single asset, etc. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"b823rREn8xDQ","colab":{}},"source":["doPrediction = True\n","doPortfolio1 = True\n","doPortfolio2 = True\n","doPortfolio3 = True\n","doPortfolio4 = True\n","doPortfolio5 = True\n","doPortfolio6 = True\n","doPortfolio7 = True\n","doPrices = True\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KTkwWgp0IKdp","outputId":"96f2a1f5-ff88-446f-ce91-fb2c7bec4dcb","executionInfo":{"status":"ok","timestamp":1589807631069,"user_tz":240,"elapsed":99638,"user":{"displayName":"Xiaoyu Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYb2XrHzjJJMEznZMIpAWInIKxnQ4P07KKtgZh=s64","userId":"13326746028563113786"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oqY-j9Ed8xDT","outputId":"ad8709e9-93ae-4b86-aa62-29ccc5278e87","executionInfo":{"status":"error","timestamp":1589808720472,"user_tz":240,"elapsed":1731,"user":{"displayName":"Xiaoyu Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgYb2XrHzjJJMEznZMIpAWInIKxnQ4P07KKtgZh=s64","userId":"13326746028563113786"}},"colab":{"base_uri":"https://localhost:8080/","height":467}},"source":["\n","# MAIN code starts here\n","long_only_values = [True,False]\n","exclude_citi_values = [False,True]\n","financials_only = [False,True]\n","combos = list(itertools.product(long_only_values, exclude_citi_values, financials_only))\n","\n","for c in range(len(combos)):\n","    print('*** Beginning Loop ***')\n","    \n","    combo = combos[c]\n","    long_only = combo[0]\n","    exclude_citi = combo[1]\n","    financials = combo[2]\n","    print('Long Only: ' + str(long_only))\n","    print('Exclude Citi: ' + str(exclude_citi))\n","    print('Financials: ' + str(financials))\n","\n","\n","    if (financials):    \n","        ticker = ['WellsFargo', 'GoldmanSachs', 'BankOfAmerica', 'BerkshireHathaway', 'Blackrock', 'BNYMellon', 'Citigroup', 'JPMorgan', 'MorganStanley']\n","    else:\n","        ticker = ['WellsFargo', 'GoldmanSachs', 'BankOfAmerica', 'BerkshireHathaway', 'Blackrock', 'BNYMellon', 'Citigroup', 'JPMorgan', 'MorganStanley','Adobe', 'Apple', 'NVIDIA']\n","    \n","    os.chdir(\"/content/drive/My Drive/FinalData\")\n","\n","    dataset = []\n","    for i in range(len(ticker)):\n","        df = pd.read_excel(ticker[i] + '_Final.xlsx')\n","        print(ticker[i])\n","        print('Total dataset has {} days, and {} features.'.format(df.shape[0], df.shape[1]))\n","        #a list with each element as a df of a single stock\n","        dataset.append(df)\n","    \n","    datasetDates = [] # a list with each element as the column 'Date' of each stock \n","    \n","    for item in dataset:\n","        datasetDates.append(item['Date'])\n","        del item['Date']\n","\n","\n","    trainingStartDate = datetime(2004,1,1)\n","    portfolioStartDate = datetime(2010,1,1)\n","    \n","    if (financials):\n","        portfolioStopDate = datetime(2018,1,1)\n","    else:\n","        portfolioStopDate = datetime(2019,11,1)\n","\n","    currDate = portfolioStartDate\n","\n","    predColumns = ['Date']     #  a list with the first element as 'Date' and remaning element as names of stocks\n","    for i in range(len(ticker)):\n","        predColumns.append(ticker[i])\n","    predDf = pd.DataFrame(columns = predColumns) # a df each line representing date and prediction of different stocks on that certain date\n","    predDfROA = pd.DataFrame(columns = predColumns)\n","    predDfFCF = pd.DataFrame(columns = predColumns)\n","    predDfROE = pd.DataFrame(columns = predColumns)\n","    \n","    os.chdir(\"/content/drive/My Drive/Results_try\")\n","    \n","    predFile = 'predictions.xlsx'\n","    print('*** Beginning Prediction Phase ***')\n","    if (doPrediction):\n","        retrain = False\n","        regressorDict = {}\n","        regressorDictROA = {}\n","        regressorDictFCF = {}\n","        regressorDictROE = {}\n","        while (currDate <= portfolioStopDate):\n","            print(currDate)\n","            currDateDict = {'Date': currDate} # this is for eps\n","            currDateDictROA = {'Date': currDate}\n","            currDateDictFCF = {'Date': currDate}\n","            currDateDictROE = {'Date': currDate}\n","\n","            for i in range(len(dataset)):\n","                #loop over all stocks\n","                df = dataset[i]\n","                dfDates = datasetDates[i]\n","    \n","                (X_train, Y_train), (X_test, Y_test) = getDataUntilDate(df, dfDates, trainingStartDate, currDate)        \n","                \n","                if (retrain or (currDate == portfolioStartDate)):\n","                    m1 = Model(X_train, Y_train, X_test, Y_test)\n","                    xgbModel, regressor = m1.trainModel(verbose_flag=False)\n","                    regressorDict[i] = regressor\n","                else:\n","                    regressor = regressorDict[i]\n","                    \n","                prediction = np.average(regressor.predict(X_test))\n","                currDateDict[predColumns[i+1]] = prediction\n","            #currDateDict = {'Date': '2010-10-01', 'Apple':10, 'Amazon':20,....}\n","            predDf = predDf.append(currDateDict, ignore_index=True)\n","\n","            for i in range(len(dataset)):\n","                df = dataset[i]\n","                dfDates = datasetDates[i]\n","    \n","                (X_train, Y_train), (X_test, Y_test) = getDataUntilDateforROA(df, dfDates, trainingStartDate, currDate)        \n","                \n","                if (retrain or (currDate == portfolioStartDate)):\n","                    m1 = Model(X_train, Y_train, X_test, Y_test)\n","                    xgbModel, regressor = m1.trainModel(verbose_flag=False)\n","                    regressorDictROA[i] = regressor\n","                else:\n","                    regressor = regressorDictROA[i]\n","                    \n","                prediction = np.average(regressor.predict(X_test))\n","                currDateDictROA[predColumns[i+1]] = prediction\n","                \n","            predDfROA = predDfROA.append(currDateDictROA, ignore_index=True)\n","\n","            for i in range(len(dataset)):\n","                #print(\"In Dataset of \" + str(ticker[i]))\n","                df = dataset[i]\n","                dfDates = datasetDates[i]\n","    \n","                (X_train, Y_train), (X_test, Y_test) = getDataUntilDateforFCF(df, dfDates, trainingStartDate, currDate)        \n","                \n","                if (retrain or (currDate == portfolioStartDate)):\n","                    m1 = Model(X_train, Y_train, X_test, Y_test)\n","                    xgbModel, regressor = m1.trainModel(verbose_flag=False)\n","                    regressorDictFCF[i] = regressor\n","                else:\n","                    regressor = regressorDictFCF[i]\n","                    \n","                prediction = np.average(regressor.predict(X_test))\n","                currDateDictFCF[predColumns[i+1]] = prediction\n","                \n","            predDfFCF = predDfFCF.append(currDateDictFCF, ignore_index=True)\n","\n","            for i in range(len(dataset)):\n","                #print(\"In Dataset of \" + str(ticker[i]))\n","                df = dataset[i]\n","                dfDates = datasetDates[i]\n","    \n","                (X_train, Y_train), (X_test, Y_test) = getDataUntilDateforROE(df, dfDates, trainingStartDate, currDate)        \n","                \n","                if (retrain or (currDate == portfolioStartDate)):\n","                    m1 = Model(X_train, Y_train, X_test, Y_test)\n","                    xgbModel, regressor = m1.trainModel(verbose_flag=False)\n","                    regressorDictROE[i] = regressor\n","                else:\n","                    regressor = regressorDictROE[i]\n","                    \n","                prediction = np.average(regressor.predict(X_test))\n","                currDateDictROE[predColumns[i+1]] = prediction\n","                \n","            predDfROE = predDfROE.append(currDateDictROE, ignore_index=True)\n","\n","                \n","            if (currDate.month == 12):\n","                currDate = datetime(currDate.year+1, 1, 1)   \n","            else:\n","                currDate = datetime(currDate.year, currDate.month+1, 1)  \n","        \n","        predDf.to_excel(predFile)\n","        \n","    predDf = pd.read_excel(predFile)\n","        \n","    print('*** Beginning Construction Phase ***')\n","    \n","    combo = combos[c]\n","    long_only = combo[0]\n","    exclude_citi = combo[1]\n","\n","    weight1File = 'weights1_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    weight2File = 'weights2_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    weight3File = 'weights3_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    weight4File = 'weights4_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    weight5File = 'weights5_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    weight6File = 'weights6_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    weight7File = 'weights7_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    imageFile = 'plot_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.png'\n","\n","    if (doPortfolio1):\n","        weight1Df = createPortfolio1(predDf, dataset, datasetDates, long_only = long_only, exclude_citi = exclude_citi)\n","        weight1Df.to_excel(weight1File)\n","    weight1Df = pd.read_excel(weight1File)\n","        \n","    if (doPortfolio2):\n","        weight2Df = createPortfolio2(predDf, dataset, datasetDates, long_only = long_only, exclude_citi = exclude_citi)\n","        weight2Df.to_excel(weight2File)\n","    weight2Df = pd.read_excel(weight2File)\n","        \n","    if (doPortfolio3):\n","        weight3Df = createPortfolio3(predDf, dataset, datasetDates, long_only = long_only, exclude_citi = exclude_citi)\n","        weight3Df.to_excel(weight3File)\n","    weight3Df = pd.read_excel(weight3File)\n","\n","    if (doPortfolio4):\n","        weight4Df = createPortfolio4(predDf, dataset, datasetDates, long_only = long_only, exclude_citi = exclude_citi)\n","        weight4Df.to_excel(weight4File)\n","    weight4Df = pd.read_excel(weight4File)\n","\n","    if (doPortfolio5):\n","        weight5Df = createPortfolio5(predDf, dataset, datasetDates, long_only = long_only, exclude_citi = exclude_citi)\n","        weight5Df.to_excel(weight5File)\n","    weight5Df = pd.read_excel(weight3File)\n","\n","    if (doPortfolio6):\n","        weight6Df = createPortfolio6(predDf, dataset, datasetDates, long_only = long_only, exclude_citi = exclude_citi)\n","        weight6Df.to_excel(weight6File)\n","    weight6Df = pd.read_excel(weight6File)\n","\n","    if (doPortfolio7):\n","        weight7Df = createPortfolio7(predDf, predDfROA, predDfFCF, predDfROE, dataset, datasetDates, long_only = long_only, exclude_citi = exclude_citi)\n","        weight7Df.to_excel(weight7File)\n","    weight7Df = pd.read_excel(weight7File)\n","    \n","    weights = [weight1Df, weight2Df, weight3Df, weight4Df, weight5Df, weight6Df, weight7Df]  \n","\n","    print('*** Beginning Return Calc Phase ***')\n","    \n","    pricesFile = 'prices_' + str(long_only) + '_' + str(exclude_citi) + '_' + str(financials) + '.xlsx'\n","    if (doPrices):\n","        prices = calcReturns(weights, dataset, datasetDates)\n","        pd.DataFrame(prices).to_excel(pricesFile)\n","    prices = pd.read_excel(pricesFile)\n","    \n","    print('*** Beginning Analytics Phase ***')\n","    \n","    if (financials):\n","        spPrices = pd.read_excel('SPF prices.xls')\n","    else:\n","        spPrices = pd.read_excel('SPX prices.xls')\n","    \n","    title = ('Financials ' if financials else 'All Sectors ') + ' - '\n","    title = title + ('Long Only' if long_only else 'Long Short')\n","    title = title + ' - '\n","    title = title + ('No Citi' if exclude_citi else 'With Citi')\n","    \n","    relatives, absolutes, trackingErrors, alphas, ir, returns, vols, sharpes, spCleanPrices = \\\n","        plotAgainstSP(prices, weights[0], spPrices, title = title, imageFile = imageFile)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["*** Beginning Loop ***\n","Long Only: True\n","Exclude Citi: False\n","Financials: False\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-6858cfe5ea39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_Final.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total dataset has {} days, and {} features.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'WellsFargo_Final.xlsx'"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CrIB6JTjIE71","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}